import os
import io
import time
import json
import random
import hashlib
import datetime
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import mysql.connector
import pdfplumber
import docx
import pytesseract
from PIL import Image
from datetime import date, datetime
from Component.Analysis_record.analysis_recoreds_ops import get_resume_score_detail_by_analysis_id
from Component.ResumeAnalysis.resume_processor import ResumeProcessor

import Component as co
from Component import get_user_resumes, get_resume_analysis, delete_analysis, get_all_jobs, get_job_by_id, get_all_models
from Component.ResumeManeger.resume_ops_mysql import update_json_resume_data
from oputils.db_config import DB_CONFIG
from oputils.secret import decrypt_api_key
from oputils.haxi import calculate_file_hash
from Component.ResumeAnalysis.resume_anaops_mysql import get_resume_json_by_resume_id, save_analysis_result
from zhipuapi import call_gpt_model

api_name = api_url = decode_apikey = job_data = score_dict =job_data_row= None

# ...ï¼ˆçœç•¥ import éƒ¨åˆ†ï¼‰

def display_analysis(phonenumber, username):
    st.title("ğŸ“Š ç®€å†åˆ†æä¸­å¿ƒ")

    resumes = co.get_user_resumes(phonenumber)
    if not resumes:
        st.info("æš‚æ— ç®€å†ï¼Œè¯·ä¸Šä¼ ã€‚")
        return

    resume_dict = {row[1]: row[0] for row in resumes}
    resume_name = st.selectbox("è¯·é€‰æ‹©è¦åˆ†æçš„ç®€å†", list(resume_dict.keys()))
    resume_id = resume_dict[resume_name]
    resume = co.get_resume_by_id(resume_id)

    def resume_analysis_page(phonenumber):
        st.markdown("---")

        api_name = api_url = decode_apikey = job_data = choose_job = None
        co1, co2 = st.columns([1, 1])
        with co1:
            jobs = co.get_all_jobs()
            job_options = [f"{job[1]} - {job[2]}" for job in jobs]
            job_mapping = {f"{job[1]} - {job[2]}": job[0] for job in jobs}

            selected_job_label = st.selectbox("é€‰æ‹©èŒä½", job_options, index=0)

            if st.button("â• åˆ›å»ºæ–°èŒä½"):
                st.switch_page("job_management_page")

            job_description = ""
            if selected_job_label:
                job_id = job_mapping[selected_job_label]
                job_data_row = co.get_job_by_id(job_id)
                # st.success(f"å·²é€‰èŒä½ï¼š{job_data_row[0]} ")
                job_description = job_data_row[3]
                choose_job = f"{job_data_row[1]} - {job_data_row[2]}"
                st.success(f"å·²é€‰èŒä½ï¼š{choose_job}")
                job_data = f"{choose_job} - {job_description}"

        with co2:
            models = co.get_all_models(phonenumber)
            model_options = [model['api_name'] for model in models]
            model_mapping = {model['api_name']: model for model in models}

            selected_model_label = st.selectbox("é€‰æ‹©æ¨¡å‹", model_options, index=0)

            if selected_model_label:
                model_info = model_mapping[selected_model_label]
                api_name = model_info["api_name"]
                api_url = model_info["api_url"]
                api_key = model_info["api_key"]
                decode_apikey = decrypt_api_key(api_key)
                st.success(f"å·²é€‰æ¨¡å‹ï¼š{api_name}")

        if selected_job_label and selected_model_label:
            st.write(f"ç®€å†è·¯å¾„ï¼š{resume[4]}")

        # ä¿®æ”¹è¿”å›è¯­å¥ï¼Œå¢åŠ  job_data_row
        return api_name, api_url, decode_apikey, job_data, choose_job, job_data_row


    # ä¿®æ”¹ unpack å˜é‡ï¼Œæ·»åŠ  job_data_row
    api_name, api_url, decode_apikey, job_data, choose_job, job_data_row = resume_analysis_page(phonenumber)


    def process_resume_main(file_path, resume_id, job_data, api_url, api_key, api_name, phonenumber, job_data_raw,choose_job):
        processor = ResumeProcessor(phonenumber=phonenumber)

        # âœ… å…ˆå°è¯•ä»æ•°æ®åº“è¯»å–ç»“æ„åŒ–ç®€å†
        structured_resume = get_resume_json_by_resume_id(resume_id)

        # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰å·²è§£ææ•°æ®ï¼Œåˆ™æå–æ–‡æœ¬å¹¶è°ƒç”¨å¤§æ¨¡å‹è§£æ
        if not structured_resume:
            raw_text = processor.extract_text(file_path)
            structured_resume = processor.structure_resume_content(raw_text, api_url, api_key, api_name)
            st.success("âœ… ç»“æ„åŒ–ç®€å†å®Œæˆ")
            if structured_resume:
                update_json_resume_data(resume_id, structured_resume)


        def stringify_dict(d):
            return {k: ", ".join(v) if isinstance(v, list) else str(v) for k, v in d.items()}

        safe_resume = stringify_dict(structured_resume)
        resume_df = pd.DataFrame(safe_resume.items(), columns=["å­—æ®µ", "å†…å®¹"])
        st.subheader("ç»“æ„åŒ–ç®€å†å†…å®¹")
        st.table(resume_df)

        structured_jobrequirements = processor.structure_job_requirements(job_data, api_url, api_key, api_name)
        st.success("âœ… ç»“æ„åŒ–å²—ä½å®Œæˆ")

        safe_job = stringify_dict(structured_jobrequirements)
        job_df = pd.DataFrame(safe_job.items(), columns=["å­—æ®µ", "è¦æ±‚"])
        st.subheader("ğŸ§¾ ç»“æ„åŒ–å²—ä½è¦æ±‚")
        st.table(job_df)

        st.write("ğŸ“ ç®€å†ä¸å²—ä½åŒ¹é…è¯„åˆ†")
        score_dict = processor.score_resume_with_llm(structured_resume, structured_jobrequirements, api_url, api_key, api_name)
        st.success("âœ… åŒ¹é…è¯„åˆ†å®Œæˆ")

        outcome = f"""è¯¥ç®€å†çš„æ•´ä½“è¯„åˆ†ä¸º {int(sum(score_dict.values()) / len(score_dict))} åˆ†ã€‚å„é¡¹å¾—åˆ†å¦‚ä¸‹ï¼š
- æ•™è‚²: {score_dict['education_score']} åˆ†
- æŠ€èƒ½: {score_dict['skills_score']} åˆ†
- ç»éªŒ: {score_dict['experience_score']} åˆ†
- è¯ä¹¦: {score_dict['certifications_score']} åˆ†
- ä¸ªäººå“è´¨: {score_dict['personal_qualities_score']} åˆ†
"""
        
        st.info(outcome)
        job_id =job_data_row[0]
        json_analysis_result = str(score_dict)
        analysis_id = processor.save_analysis_result(resume_id, score_dict, job_id, outcome,json_analysis_result,state="å·²å®Œæˆ")
        
        co.save_resume_score_detail(analysis_id=analysis_id,
                                    score_data=score_dict,
                                    job_name=choose_job
                                    )
# {'education_score': 80, 'knowledge_score': 70, 'certification_score': 50, 'personal_quality_score': 75, 'experience_score': 85}
        return analysis_id, score_dict, structured_resume, outcome
    file_path=resume[4]
    if st.button("å¼€å§‹åˆ†æ"):
        process_resume_main(file_path, resume_id, job_data, api_url, decode_apikey, api_name, phonenumber,job_data_row,choose_job)

    st.markdown("---")

    with st.expander("ğŸ“… åˆ†æè®°å½•ç­›é€‰ï¼ˆæŒ‰æ—¥æœŸï¼‰", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            start_date = st.date_input("å¼€å§‹æ—¥æœŸ", value=date(2024, 1, 1))
        with col2:
            end_date = st.date_input("ç»“æŸæ—¥æœŸ", value=date.today())

    analysis_records = co.get_resume_analysis(
        resume_id=resume_id,
        start_date=start_date.strftime("%Y-%m-%d"),
        end_date=end_date.strftime("%Y-%m-%d")
    )

    df = pd.DataFrame(analysis_records, columns=["ID", "åˆ†æ•°", "åˆ†ææ—¶é—´", "ç»“æœ", "çŠ¶æ€"])

    if df.empty:
        st.info("è¯¥ç®€å†åœ¨æ‰€é€‰æ—¶é—´æ®µå†…æš‚æ— åˆ†æè®°å½•ã€‚")
    else:
        st.subheader("ğŸ“„ åˆ†æè®°å½•")
        st.dataframe(df, use_container_width=True)

        export_format = st.radio("å¯¼å‡ºæ ¼å¼", ["CSV", "Excel"], horizontal=True)
        if st.button("ğŸ“¤ å¯¼å‡ºåˆ†æè®°å½•"):
            if export_format == "CSV":
                st.download_button("ç‚¹å‡»ä¸‹è½½ CSV æ–‡ä»¶", df.to_csv(index=False).encode('utf-8'), file_name="analysis.csv")
            else:
                towrite = io.BytesIO()
                df.to_excel(towrite, index=False, engine='openpyxl')
                towrite.seek(0)
                st.download_button("ç‚¹å‡»ä¸‹è½½ Excel æ–‡ä»¶", towrite, file_name="analysis.xlsx")

        # å›¾è¡¨å±•ç¤º
        plt.rcParams['font.sans-serif'] = ['SimHei']
        plt.rcParams['axes.unicode_minus'] = False
        pic1, pic2, pic3 = st.columns([1, 1, 1])

        with pic1:
            st.subheader("ğŸ¯ åˆ†æ•°åˆ†å¸ƒå›¾")
            plt.clf()
            plt.figure(figsize=(6, 3))
            sns.histplot(df["åˆ†æ•°"], kde=True, bins=10, color="skyblue")
            plt.xlabel("åˆ†æåˆ†æ•°")
            st.pyplot(plt)

        with pic2:
            st.subheader("ğŸ“ˆ åˆ†æè¶‹åŠ¿å›¾")
            plt.clf()
            df["åˆ†ææ—¶é—´"] = pd.to_datetime(df["åˆ†ææ—¶é—´"])
            df_sorted = df.sort_values("åˆ†ææ—¶é—´")
            plt.figure(figsize=(6, 3))
            sns.lineplot(data=df_sorted, x="åˆ†ææ—¶é—´", y="åˆ†æ•°", marker="o", color="orange")
            plt.xticks(rotation=45)
            plt.tight_layout()
            st.pyplot(plt)

        with pic3:
            st.subheader("ğŸ“Š é›·è¾¾å›¾")
            processor = ResumeProcessor(phonenumber=phonenumber)

            options = [
                f"ID:{record[0]} - åˆ†æ•°:{record[1]} - æ—¶é—´:{record[2].strftime('%Y-%m-%d %H:%M:%S')}"
                for record in analysis_records
            ]

            selected_option = st.selectbox("é€‰æ‹©åˆ†æè®°å½•", options, index=0)
            selected_analysis_id = int(selected_option.split(" ")[0].split(":")[1])

            score_dict = get_resume_score_detail_by_analysis_id(selected_analysis_id)
            if score_dict:
                st.write(score_dict)
                processor.plot_score_radar(score_dict)
            else:
                st.info("è¯¥åˆ†æè®°å½•æš‚æ— è¯„åˆ†è¯¦æƒ…æ•°æ®ã€‚")

    with st.expander("ğŸ—‘ï¸ åˆ é™¤åˆ†æè®°å½•"):
        if not df.empty:
            del_id = st.selectbox("é€‰æ‹©è¦åˆ é™¤çš„è®°å½• ID", df["ID"])
            if st.button("ç¡®è®¤åˆ é™¤è®°å½•"):
                co.delete_analysis(del_id)
                st.success("åˆ é™¤æˆåŠŸ")
                st.experimental_rerun()
